{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> `Video RAG`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `Video resolution`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Video resolution` is the size of each image in the video. It doesn't need to be a standard size, but there are common sizes for video.\n",
    "\n",
    "`Frame rate` determines the number of `images` seen per second. Can be described as `fps` (frames per second) or `Hz` (general unit for frequency)\n",
    "\n",
    "<center> <img src = \"/Users/glebmaksimov/Desktop/ML/projects/video_rag/docs/video.png\" height = 300>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, torch, warnings, collections, spacy, os\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from numpy import dot\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go \n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Dim Red\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Clustering\n",
    "\n",
    "import hdbscan\n",
    "from sklearn.cluster import DBSCAN,KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_lg\") \n",
    "\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore'); RANDOM_SEED = 42; device  = \"cpu\" \n",
    "pd.set_option(\"display.max_rows\", 600)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"max_colwidth\", 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"/Users/glebmaksimov/Desktop/ML/projects/video_rag/docs/Coding LLaMA 2 from scratch in PyTorch - KV Cache, Grouped Query Attention, Rotary PE, RMSNorm.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text \n",
    "\n",
    "def embed(texts):\n",
    "\n",
    "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "    embeddings = model.encode(texts)\n",
    "\n",
    "    return embeddings \n",
    "\n",
    "def chunk_text(text, chunk_size = 300, chunk_overlap = 50):\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "    len_f = lambda x : len(tokenizer(x, padding = True, truncation = True, return_tensors = 'pt')[\"input_ids\"][0])\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "            \n",
    "                                                        chunk_size      = chunk_size,\n",
    "                                                        chunk_overlap   = chunk_overlap,\n",
    "                                                        length_function = len_f,\n",
    "                                                        separators      = [\". \",\"! \",\"; \",\"? \",\",\",\" \", \"\"]\n",
    "                                                    )\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def cosine_similarity(list_1, list_2):\n",
    "  \n",
    "  cos_sim = dot(list_1, list_2) / (norm(list_1) * norm(list_2))\n",
    "  \n",
    "  return cos_sim\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Video\n",
    "# -----------------------------------------------\n",
    "\n",
    "def get_video_specs(video):\n",
    "\n",
    "    cap = cv2.VideoCapture(video)\n",
    "\n",
    "    n_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    height   = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    width    = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    fps      = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    return cap, n_frames, height, width, fps\n",
    "\n",
    "def extract_frames(video):\n",
    "\n",
    "    cap,n_frames,_,_,_ =  get_video_specs(video)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(int(n_frames)):\n",
    "\n",
    "        ret, img = cap.read()\n",
    "\n",
    "        if ret == False: break\n",
    "\n",
    "        frames.append(img)\n",
    "    \n",
    "    cap.release() # plt.imshow(cv2.cvtColor(images[1035], cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    return frames\n",
    "\n",
    "def mp4_to_mp3(video):\n",
    "    \n",
    "    # Define the input video file and output audio file\n",
    "    mp4_file = video\n",
    "    mp3_file = video.replace(\".mp4\",\".mp3\")\n",
    "\n",
    "    # Load the video clip\n",
    "    video_clip = VideoFileClip(mp4_file)\n",
    "\n",
    "    # Extract the audio from the video clip\n",
    "    audio_clip = video_clip.audio\n",
    "\n",
    "    # Write the audio to a separate file\n",
    "    audio_clip.write_audiofile(mp3_file)\n",
    "\n",
    "    # Close the video and audio clips\n",
    "    audio_clip.close()\n",
    "    video_clip.close()\n",
    "\n",
    "    print(\"Audio extraction successful!\")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Audio\n",
    "# -----------------------------------------------\n",
    "\n",
    "def get_mp3_length(file_path):\n",
    "    \n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "\n",
    "    return len(audio)/ 1000.0\n",
    "\n",
    "def chunk_audio(audio, output_dir, chunk_size = 300, chunk_overlap = 50):\n",
    "    \n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_mp3(audio)\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Calculate segment length and overlap in milliseconds\n",
    "    segment_length_ms = chunk_size * 1000\n",
    "    overlap_ms = chunk_overlap * 1000\n",
    "\n",
    "    # Initialize start and end times\n",
    "    start = 0\n",
    "    end = segment_length_ms\n",
    "\n",
    "    segment_number = 1\n",
    "\n",
    "    # Split audio with overlap\n",
    "    while start < len(audio):\n",
    "        # Extract segment\n",
    "        segment = audio[start:end]\n",
    "        # Export segment to file\n",
    "        segment.export(os.path.join(output_dir, f\"segment_{segment_number}.mp3\"), format=\"mp3\")\n",
    "        \n",
    "        # Update start and end times for next segment\n",
    "        start += segment_length_ms - overlap_ms\n",
    "        end = start + segment_length_ms\n",
    "\n",
    "        segment_number += 1\n",
    "\n",
    "        # Break if the end goes beyond the audio length\n",
    "        if start >= len(audio):\n",
    "            break\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Clustering\n",
    "# -----------------------------------------------\n",
    " \n",
    "def normalize_embeddings(embeddings): return embeddings / np.linalg.norm(embeddings, axis=1).max()\n",
    "\n",
    "def reduce_dimentionality(embeddings, n_neighbors, n_components, decomposition_algorithm):\n",
    "    \n",
    "    normed_embeddings = normalize_embeddings(embeddings)\n",
    "\n",
    "    if decomposition_algorithm == \"UMAP\": return umap.UMAP(  n_neighbors  = n_neighbors, \n",
    "                                                             n_components = n_components,\n",
    "                                                             metric       = \"euclidean\",\n",
    "                                                             min_dist     = 0.3,\n",
    "                                                             n_jobs       = -1, \n",
    "                                                             random_state = RANDOM_SEED\n",
    "                                                           ).fit_transform(normed_embeddings)\n",
    "\n",
    "    # elif decomposition_algorithm == \"T-SNE\": return TSNE(   n_components = n_components, \n",
    "    #                                                         n_jobs = -1,\n",
    "    #                                                         random_state = RANDOM_SEED,\n",
    "    #                                                         metric = \"euclidean\",\n",
    "    #                                                         method='exact'\n",
    "    #                                                     ).fit_transform(normed_embeddings)\n",
    "\n",
    "    elif decomposition_algorithm == \"PCA\": return PCA(n_components = n_components, random_state = RANDOM_SEED).fit_transform(normed_embeddings)\n",
    "\n",
    "def generate_clusters(*args):\n",
    "    \n",
    "    decomposed_embeddings = reduce_dimentionality(  embeddings               = args[0], \n",
    "                                                    n_neighbors              = args[1],\n",
    "                                                    n_components             = 3,\n",
    "                                                    decomposition_algorithm  = args[4])\n",
    "    \n",
    "    decomposed_embeddings = normalize_embeddings(decomposed_embeddings)\n",
    "\n",
    "    if args[6] == \"HDBSCAN\": return hdbscan.HDBSCAN(    min_cluster_size         = args[2],\n",
    "                                                        min_samples              = args[3],\n",
    "                                                        metric                   = \"euclidean\",\n",
    "                                                        core_dist_n_jobs         = -1,\n",
    "                                                        cluster_selection_method = \"eom\"\n",
    "                                                    ).fit(decomposed_embeddings), decomposed_embeddings\n",
    "\n",
    "    else: return DBSCAN(eps=args[5], min_samples = args[3], n_jobs = -1, metric = \"euclidean\").fit(decomposed_embeddings), decomposed_embeddings\n",
    "        \n",
    "def score_clusters(embeddings, clusters):\n",
    "\n",
    "    labels = clusters.labels_\n",
    "     \n",
    "    n_labels = len(set(labels))\n",
    "\n",
    "    n_clusters = n_labels - (1 if -1 in labels else 0)\n",
    "    \n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    if n_labels > 1: \n",
    "        \n",
    "        calinski_harabasz_score = metrics.calinski_harabasz_score(embeddings, labels)\n",
    "        silhouette_score        = metrics.silhouette_score(embeddings, labels)\n",
    "        davies_bouldin_score    = metrics.davies_bouldin_score(embeddings, labels)\n",
    "        # DBCV_score =              DBCV(data, clusters, dist_function=euclidean)\n",
    "\n",
    "\n",
    "    else: calinski_harabasz_score, davies_bouldin_score, silhouette_score = -1, np.inf, -1\n",
    "        \n",
    "    return labels, n_labels, n_clusters, n_noise, calinski_harabasz_score, silhouette_score, davies_bouldin_score \n",
    "\n",
    "def greed_search(embeddings, decomposition_algorithm, clustering_algorithm, min_cluster_size, space):\n",
    "    \n",
    "    trials = { \n",
    "                            \"decomposition_algorithm\":             [],\n",
    "                            \"n_neighbours\":                        [],\n",
    "                            \"clustring_algorithm\":                 [],\n",
    "                            \"min_samples\":                         [],\n",
    "                            \"eps\":                                 [], \n",
    "                            \"n_labels\":                            [],\n",
    "                            \"n_clusters\":                          [], \n",
    "                            \"n_noise\":                             [],\n",
    "                            \"calinski_harabasz_score -> max\" :     [],\n",
    "                            \"silhouette_score [-1,1] -> max\":      [],\n",
    "                            \"davies_bouldin_score [0,inf] -> min\": [],\n",
    "                            \"decomposed_embeddings\":               [],\n",
    "                            \"labels\":                              [],\n",
    "    }\n",
    "    \n",
    "    for n_neighbors in space[\"n_neighbors\"]:\n",
    "            \n",
    "            for min_samples in space[\"min_samples\"]:\n",
    "                    \n",
    "                    for eps in space[\"eps\"]:\n",
    "                        \n",
    "                        clusters, decomposed_embeddings = generate_clusters(embeddings, n_neighbors, min_cluster_size, min_samples, decomposition_algorithm, eps, clustering_algorithm)\n",
    "\n",
    "                        # labels, n_labels, n_clusters, n_noise, calinski_harabasz_score, silhouette_score, davies_bouldin_score, dbcv_score = score_clusters(embeddings, clusters)\n",
    "                        labels, n_labels, n_clusters, n_noise, calinski_harabasz_score, silhouette_score, davies_bouldin_score = score_clusters(embeddings, clusters)\n",
    "\n",
    "                        new_entry = {\n",
    "                             \n",
    "                            \"decomposition_algorithm\":             decomposition_algorithm,\n",
    "                            \"n_neighbours\":                        n_neighbors,\n",
    "                            \"clustring_algorithm\":                 clustering_algorithm,\n",
    "                            \"min_samples\":                         min_samples,\n",
    "                            \"eps\":                                 eps, \n",
    "                            \"n_labels\":                            n_labels,\n",
    "                            \"n_clusters\":                          n_clusters, \n",
    "                            \"n_noise\":                             n_noise,\n",
    "                            \"calinski_harabasz_score -> max\" :     calinski_harabasz_score,\n",
    "                            \"silhouette_score [-1,1] -> max\":      silhouette_score,\n",
    "                            \"davies_bouldin_score [0,inf] -> min\": davies_bouldin_score,\n",
    "                            # \"DBCV_score\"                          : dbcv_score,\n",
    "                            \"decomposed_embeddings\":               [decomposed_embeddings.tolist()],\n",
    "                            \"labels\":                              [labels.tolist()]}\n",
    "                        \n",
    "                        for key, value in new_entry.items(): trials[key].append(value)\n",
    "                         \n",
    "\n",
    "    return trials\n",
    "\n",
    "def get_best_params(trials):\n",
    "\n",
    "    # best_davies_bouldin_score    = trials[\"davies_bouldin_score [0,inf] -> min\"].min()\n",
    "    # best_silhouette_score_score  = trials[\"silhouette_score [-1,1] -> max\"].max()\n",
    "    # best_calinski_harabasz_score = trials[\"calinski_harabasz_score -> max\"].max()\n",
    "    \n",
    "    best_params = trials.sort_values(by=[\"davies_bouldin_score [0,inf] -> min\"], ascending=True).iloc[0]    \n",
    "    return best_params\n",
    "\n",
    "def plot_clusters(decomposition_algorithm, embeddings_3d, labels, n_neighbours):\n",
    "\n",
    "    embeddings_2d = reduce_dimentionality( embeddings = embeddings_3d,\n",
    "                                           n_components = 2, \n",
    "                                           decomposition_algorithm = decomposition_algorithm, \n",
    "                                           n_neighbors = n_neighbours)\n",
    "    \n",
    "    embeddings_3d = normalize_embeddings(embeddings_3d)\n",
    "    embeddings_2d = normalize_embeddings(embeddings_2d)\n",
    "\n",
    "    fig = sp.make_subplots(rows=1, cols=3, specs=[[{'type': 'scene'}, {'type': 'xy'}, {'type': 'bar'}]])\n",
    "\n",
    "    scatter_3d = go.Scatter3d(x=embeddings_3d[:, 0], y=embeddings_3d[:, 1], z=embeddings_3d[:, 2], mode='markers', marker=dict(size=5, color=labels))\n",
    "\n",
    "    fig.add_trace(scatter_3d, row=1, col=1)\n",
    "\n",
    "    scatter_2d = go.Scatter(x=embeddings_2d[:, 0], y=embeddings_2d[:, 1], mode='markers', marker=dict(size=5, color=labels))\n",
    "\n",
    "    fig.add_trace(scatter_2d, row=1, col=2)\n",
    "     \n",
    "    label_counts = list(Counter(labels).values())\n",
    "    \n",
    "    labels_ids = list(Counter(labels).keys())\n",
    "\n",
    "    bar_plot = go.Bar(x=labels_ids, y=label_counts)\n",
    "\n",
    "    fig.add_trace(bar_plot, row=1, col=3)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene=dict(aspectmode='data')\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Clusters Labeling\n",
    "\n",
    "def most_common(lst, n_words):\n",
    "    \"\"\"\n",
    "    Get most common words in a list of words\n",
    "    \n",
    "    Arguments:\n",
    "        lst: list, each element is a word\n",
    "        n_words: number of top common words to return\n",
    "    \n",
    "    Returns:\n",
    "        counter.most_common(n_words): counter object of n most common words\n",
    "    \"\"\"\n",
    "    counter=collections.Counter(lst)\n",
    "    return counter.most_common(n_words)\n",
    "\n",
    "def get_group(df, category_col, category):\n",
    "    \"\"\"\n",
    "    Returns documents of a single category\n",
    "    \n",
    "    Arguments:\n",
    "        df: pandas dataframe of documents\n",
    "        category_col: str, column name corresponding to categories or clusters\n",
    "        category: int, cluster number to return\n",
    "    Returns:\n",
    "        single_category: pandas dataframe with documents from a single category\n",
    "    \"\"\"\n",
    "    \n",
    "    single_category = df[df[category_col]==category].reset_index(drop=True)\n",
    "\n",
    "    return single_category \n",
    "\n",
    "def extract_labels(category_docs, print_word_counts=False):\n",
    "    \"\"\"\n",
    "    Extract labels from documents in the same cluster by concatenating\n",
    "    most common verbs, ojects, and nouns\n",
    "\n",
    "    Argument:\n",
    "        category_docs: list of documents, all from the same category or\n",
    "                       clustering\n",
    "        print_word_counts: bool, True will print word counts of each type in this category\n",
    "\n",
    "    Returns:\n",
    "        label: str, group label derived from concatentating most common\n",
    "               verb, object, and two most common nouns\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    verbs, dobjs, nouns, adjs = [], [], [], []\n",
    "    verb,dobj,noun1, noun2  =   '', '', '', ''\n",
    "\n",
    "    # for each document, append verbs, dobs, nouns, and adjectives to \n",
    "    # running lists for whole cluster\n",
    "    for i in range(len(category_docs)):\n",
    "\n",
    "        doc = nlp(category_docs[i])\n",
    "\n",
    "        for token in doc:\n",
    "\n",
    "            if token.is_stop==False:\n",
    "\n",
    "                if token.dep_ == 'ROOT': verbs.append(token.text.lower())\n",
    "\n",
    "                elif token.dep_=='dobj': dobjs.append(token.lemma_.lower())\n",
    "\n",
    "                elif token.pos_=='NOUN': nouns.append(token.lemma_.lower())\n",
    "                    \n",
    "                elif token.pos_=='ADJ':  adjs.append(token.lemma_.lower())\n",
    "\n",
    "    # for printing out for inspection purposes\n",
    "    if print_word_counts:\n",
    "        for word_lst in [verbs, dobjs, nouns, adjs]:\n",
    "            counter=collections.Counter(word_lst)\n",
    "            print(counter)\n",
    "    \n",
    "    # take most common words of each form\n",
    "    if len(verbs) > 0: verb = most_common(verbs, 1)[0][0]\n",
    "    \n",
    "    if len(dobjs) > 0: dobj = most_common(dobjs, 1)[0][0]\n",
    "    \n",
    "    if len(nouns) > 0: noun1 = most_common(nouns, 1)[0][0]\n",
    "    \n",
    "    if len(set(nouns)) > 1: noun2 = most_common(nouns, 2)[1][0]\n",
    "    \n",
    "    # concatenate the most common verb-dobj-noun1-noun2 (if they exist)\n",
    "    label_words = [verb, dobj]\n",
    "    \n",
    "    for word in [noun1, noun2]:\n",
    "        if word not in label_words: label_words.append(word)\n",
    "    \n",
    "    if '' in label_words: label_words.remove('')\n",
    "    \n",
    "    label = '_'.join(label_words)\n",
    "    \n",
    "    return label\n",
    "\n",
    "def apply_and_summarize_labels(df, category_col):\n",
    "    \"\"\"\n",
    "    Assign groups to original documents and provide group counts\n",
    "\n",
    "    Arguments:\n",
    "        df: pandas dataframe of original documents of interest to\n",
    "            cluster\n",
    "        category_col: str, column name corresponding to categories or clusters\n",
    "\n",
    "    Returns:\n",
    "        summary_df: pandas dataframe with model cluster assignment, number\n",
    "                    of documents in each cluster and derived labels\n",
    "    \"\"\"\n",
    "    \n",
    "    numerical_labels = df[category_col].unique()\n",
    "    \n",
    "    # create dictionary of the numerical category to the generated label\n",
    "    label_dict = {}\n",
    "    for label in numerical_labels:\n",
    "        current_category = list(get_group(df, category_col, label)['chunk'])\n",
    "        label_dict[label] = extract_labels(current_category)\n",
    "        \n",
    "    # create summary dataframe of numerical labels and counts\n",
    "    summary_df = (df.groupby(category_col)['chunk'].count()\n",
    "                    .reset_index()\n",
    "                    .rename(columns={'chunk':'count'})\n",
    "                    .sort_values('count', ascending=False))\n",
    "    \n",
    "    # apply generated labels\n",
    "    summary_df['label'] = summary_df.apply(lambda x: label_dict[x[category_col]], axis = 1)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mp4_to_mp3(video)\n",
    "\n",
    "# # text = audio_to_text()\n",
    "\n",
    "# # with open(\"/Users/glebmaksimov/Desktop/ML/projects/video_rag/docs/text.txt\", mode=\"w\") as f: f.write(text)\n",
    "\n",
    "# text = open(\"/Users/glebmaksimov/Desktop/ML/projects/video_rag/docs/text.txt\", mode = 'r').read()\n",
    "\n",
    "# chunks = chunk(text, chunk_size = 300, chunk_overlap = 50)\n",
    "\n",
    "# embeddings = embed(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decomposition_algorithms = [\"PCA\", \"UMAP\"]# \"T-SNE\" - too long and bad for noisy data\n",
    "\n",
    "# clustering_algorithms = [\"DBSCAN\", \"HDBSCAN\"]\n",
    "\n",
    "# n_neighbors      = [10, 15, 25]\n",
    "# min_samples      = [round(i) for i in np.linspace(5,15,num=3)]\n",
    "# eps              = [i for i in np.linspace(0.005,0.08,num=3)]\n",
    "\n",
    "# space = { \"n_neighbors\":      n_neighbors,\n",
    "#           \"min_samples\":      min_samples,\n",
    "#           \"eps\":              eps}\n",
    "\n",
    "# overal_scores =  pd.DataFrame({ \n",
    "#                                 \"decomposition_algorithm\":[],\n",
    "#                                 \"n_neighbours\":[],\n",
    "#                                 \"clustring_algorithm\":[],\n",
    "#                                 \"min_samples\":[],\n",
    "#                                 \"eps\":[], \n",
    "#                                 \"n_labels\": [],\n",
    "#                                 \"n_clusters\":[], \n",
    "#                                 \"n_noise\":[],\n",
    "#                                 \"calinski_harabasz_score -> max\" : [],\n",
    "#                                 \"silhouette_score [-1,1] -> max\": [],\n",
    "#                                 \"davies_bouldin_score [0,inf] -> min\":[],\n",
    "#                                 # \"DBCV_score\"                          :[]\n",
    "\n",
    "#                 })\n",
    "\n",
    "# df = pd.DataFrame({\"chunk\":chunks})\n",
    "\n",
    "# for decomposition_algorithm in decomposition_algorithms:\n",
    "\n",
    "#     for clustering_algorithm in clustering_algorithms:\n",
    "                \n",
    "#                 trials = greed_search(  embeddings = embeddings, \n",
    "#                                         space                   = space,\n",
    "#                                         min_cluster_size        = 20,\n",
    "#                                         decomposition_algorithm = decomposition_algorithm,\n",
    "#                                         clustering_algorithm    = clustering_algorithm)\n",
    "                \n",
    "#                 trials = pd.DataFrame(trials)\n",
    "\n",
    "#                 best_params = get_best_params(trials)\n",
    "\n",
    "#                 display(pd.DataFrame(trials.iloc[:,:-2].to_dict(),index = [0]))\n",
    "#                 overal_scores = pd.concat([overal_scores, trials.iloc[:,:-2]], axis = 0)\n",
    "                 \n",
    "#                 if best_params.n_labels >= 2: \n",
    "                        \n",
    "#                         df[f\"{decomposition_algorithm}:{clustering_algorithm} labels\"] = best_params.labels[0]\n",
    "\n",
    "                       \n",
    "#                         plot_clusters( decomposition_algorithm = decomposition_algorithm, \n",
    "#                                                              embeddings_3d           = best_params.decomposed_embeddings[0], \n",
    "#                                                              labels                  = best_params.labels[0], \n",
    "#                                                              n_neighbours            = best_params.n_neighbours)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "\n",
    "        task              = \"automatic-speech-recognition\",\n",
    "        model             = \"openai/whisper-small.en\",\n",
    "        device            = torch.device('cpu' if not torch.cuda.is_available() else 'cuda:0')\n",
    "    )\n",
    "\n",
    "path = \"/Users/glebmaksimov/Desktop/ML/projects/video_rag/output_segments\"\n",
    "\n",
    "files = sorted(os.listdir(path))\n",
    "\n",
    "audio_segments = {}\n",
    "\n",
    "i = 0\n",
    "\n",
    "prev_l = 0\n",
    "\n",
    "current_l = 0\n",
    "\n",
    "for f in tqdm(files, total=len(files),desc = \"Video Processing\"):\n",
    "    \n",
    "    file = path + \"/\" + f\n",
    "\n",
    "    current_l += get_mp3_length(file)\n",
    "\n",
    "    current_text = pipe(file)[\"text\"]\n",
    "\n",
    "    audio_segments[current_text] = (prev_l,current_l)\n",
    "\n",
    "    prev_l = current_l + 1\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(audio_segments.keys())\n",
    "\n",
    "embeddings = embed(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px \n",
    "\n",
    "# embeddings_3d = reduce_dimentionality(  embeddings               = embeddings, \n",
    "#                                         n_neighbors              = 10,\n",
    "#                                         n_components             = 3,\n",
    "#                                         decomposition_algorithm  = \"UMAP\")\n",
    "    \n",
    "# embeddings_3d = normalize_embeddings(embeddings_3d)\n",
    "\n",
    "# clusters = hdbscan.HDBSCAN( min_cluster_size         = 5,\n",
    "#                             min_samples              = 5,\n",
    "#                             metric                   = \"euclidean\",\n",
    "#                             core_dist_n_jobs         = -1,\n",
    "#                             cluster_selection_method = \"eom\"\n",
    "#                            ).fit(embeddings_3d)\n",
    "\n",
    "\n",
    "# labels = clusters.labels_\n",
    "\n",
    "\n",
    "# fig = px.scatter_3d(    \n",
    "#                         x        = embeddings_3d[:, 0], \n",
    "#                         y        = embeddings_3d[:, 1],\n",
    "#                         z        = embeddings_3d[:, 2],\n",
    "#                         color    = labels, #{f\"{k} label\":v for k,v in zip(labels,labels)},\n",
    "#                         height   = 700,\n",
    "#                         width    = 1500,\n",
    "#                         size_max = 5,\n",
    "#                         opacity  = 0.7,\n",
    "#                         # symbol = labels\n",
    "#                     )\n",
    "\n",
    "# fig.update_layout( margin=dict(l=0, r=0, b=0, t=0))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sse = [] \n",
    "# for k in range(1,11):\n",
    "#     km = KMeans(n_clusters=k, random_state = RANDOM_SEED)\n",
    "#     km.fit(embeddings_3d)\n",
    "#     sse.append(km.inertia_)\n",
    "\n",
    "# fig = px.line(x=range(1,11), y=sse)\n",
    " \n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans = KMeans(n_clusters = 10, random_state = 2)\n",
    "# kmeans.fit(embeddings_3d)\n",
    "\n",
    "# labels = kmeans.labels_\n",
    "\n",
    "# fig = px.scatter_3d(    \n",
    "#                         x        = embeddings_3d[:, 0], \n",
    "#                         y        = embeddings_3d[:, 1],\n",
    "#                         z        = embeddings_3d[:, 2],\n",
    "#                         color    = labels, #{f\"{k} label\":v for k,v in zip(labels,labels)},\n",
    "#                         height   = 700,\n",
    "#                         width    = 1500,\n",
    "#                         size_max = 5,\n",
    "#                         opacity  = 0.7,\n",
    "#                         # symbol = labels\n",
    "#                     )\n",
    "\n",
    "# fig.update_layout( margin=dict(l=0, r=0, b=0, t=0))\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l, ch in zip(labels,chunks):\n",
    "\n",
    "    print(f\"{l} - {ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_category = list(get_group(df, \"UMAP:HDBSCAN labels\", -1)[\"chunk\"])\n",
    "extract_labels(example_category, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary = apply_and_summarize_labels(df, \"UMAP:HDBSCAN labels\")\n",
    "cluster_summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_clusters = pd.merge(df, cluster_summary[['UMAP:HDBSCAN labels', 'label']], on='UMAP:HDBSCAN labels', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
